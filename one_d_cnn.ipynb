{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5056\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import string\n",
    "import numpy as np\n",
    "from re import search\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "regexpr = 'abcda'\n",
    "\n",
    "def encode_letter(letter):\n",
    "    if letter == \"a\":\n",
    "        return [1, 0, 0, 0]\n",
    "    elif letter == \"b\":\n",
    "        return [0, 1, 0, 0]\n",
    "    elif letter == \"c\":\n",
    "        return [0, 0, 1, 0]\n",
    "    elif letter == \"d\":\n",
    "        return [0, 0, 0, 1]\n",
    "\n",
    "strings = []\n",
    "\n",
    "population_correct = 0\n",
    "\n",
    "while population_correct < 5000:\n",
    "    random_str = ''.join(random.choices(string.ascii_lowercase[:4], k=15))\n",
    "    if search(regexpr, random_str):\n",
    "        strings.append(random_str)\n",
    "        population_correct += 1\n",
    "\n",
    "strings.extend([''.join(random.choices(string.ascii_lowercase[:4], k=15)) for i in range(5000)])\n",
    "strings = np.array(strings)\n",
    "\n",
    "labels = np.array([1 if search(regexpr, s) else 0 for s in strings])\n",
    "encoded_strings = []\n",
    "\n",
    "for s in strings:\n",
    "    encoding = np.zeros((len(s), 4))\n",
    "    for i, letter in enumerate(s):\n",
    "        encoding[i, :] = encode_letter(letter)\n",
    "    encoded_strings.append(encoding)\n",
    "encoded_strings = np.array(encoded_strings)\n",
    "print(len(list(filter(lambda x: x == 1, labels))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "strings_train, strings_test, labels_train, labels_test = train_test_split(encoded_strings, labels, test_size=0.2, shuffle=True, random_state=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d (Conv1D)              (None, 11, 1)             21        \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 12        \n",
      "=================================================================\n",
      "Total params: 33\n",
      "Trainable params: 33\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(8000, 15, 4)\n",
      "Epoch 1/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.7081 - accuracy: 0.5095 - val_loss: 0.6941 - val_accuracy: 0.5310\n",
      "Epoch 2/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.6961 - accuracy: 0.5257 - val_loss: 0.6867 - val_accuracy: 0.5380\n",
      "Epoch 3/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.6850 - accuracy: 0.5574 - val_loss: 0.6744 - val_accuracy: 0.5795\n",
      "Epoch 4/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.6660 - accuracy: 0.6106 - val_loss: 0.6522 - val_accuracy: 0.6315\n",
      "Epoch 5/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.6392 - accuracy: 0.6711 - val_loss: 0.6225 - val_accuracy: 0.6840\n",
      "Epoch 6/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.6082 - accuracy: 0.7245 - val_loss: 0.5890 - val_accuracy: 0.7470\n",
      "Epoch 7/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.5743 - accuracy: 0.7741 - val_loss: 0.5534 - val_accuracy: 0.8010\n",
      "Epoch 8/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.5390 - accuracy: 0.8130 - val_loss: 0.5144 - val_accuracy: 0.8400\n",
      "Epoch 9/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.5027 - accuracy: 0.8472 - val_loss: 0.4764 - val_accuracy: 0.8635\n",
      "Epoch 10/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8621 - val_loss: 0.4434 - val_accuracy: 0.8895\n",
      "Epoch 11/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.4367 - accuracy: 0.8796 - val_loss: 0.4092 - val_accuracy: 0.8935\n",
      "Epoch 12/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.4068 - accuracy: 0.8905 - val_loss: 0.3805 - val_accuracy: 0.9010\n",
      "Epoch 13/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.3808 - accuracy: 0.9009 - val_loss: 0.3551 - val_accuracy: 0.9170\n",
      "Epoch 14/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.3575 - accuracy: 0.9079 - val_loss: 0.3323 - val_accuracy: 0.9220\n",
      "Epoch 15/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.3347 - accuracy: 0.9155 - val_loss: 0.3048 - val_accuracy: 0.9285\n",
      "Epoch 16/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.2981 - accuracy: 0.9308 - val_loss: 0.2650 - val_accuracy: 0.9540\n",
      "Epoch 17/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.2602 - accuracy: 0.9504 - val_loss: 0.2307 - val_accuracy: 0.9630\n",
      "Epoch 18/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.2238 - accuracy: 0.9625 - val_loss: 0.1952 - val_accuracy: 0.9725\n",
      "Epoch 19/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1900 - accuracy: 0.9675 - val_loss: 0.1666 - val_accuracy: 0.9735\n",
      "Epoch 20/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1633 - accuracy: 0.9701 - val_loss: 0.1448 - val_accuracy: 0.9755\n",
      "Epoch 21/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.1410 - accuracy: 0.9730 - val_loss: 0.1263 - val_accuracy: 0.9775\n",
      "Epoch 22/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9754 - val_loss: 0.1098 - val_accuracy: 0.9780\n",
      "Epoch 23/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.1059 - accuracy: 0.9761 - val_loss: 0.0959 - val_accuracy: 0.9785\n",
      "Epoch 24/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0920 - accuracy: 0.9779 - val_loss: 0.0847 - val_accuracy: 0.9845\n",
      "Epoch 25/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0809 - accuracy: 0.9845 - val_loss: 0.0750 - val_accuracy: 0.9905\n",
      "Epoch 26/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0716 - accuracy: 0.9901 - val_loss: 0.0667 - val_accuracy: 0.9945\n",
      "Epoch 27/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0635 - accuracy: 0.9958 - val_loss: 0.0591 - val_accuracy: 0.9960\n",
      "Epoch 28/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0560 - accuracy: 0.9971 - val_loss: 0.0522 - val_accuracy: 0.9965\n",
      "Epoch 29/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0492 - accuracy: 0.9974 - val_loss: 0.0460 - val_accuracy: 0.9970\n",
      "Epoch 30/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0431 - accuracy: 0.9974 - val_loss: 0.0403 - val_accuracy: 0.9975\n",
      "Epoch 31/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0377 - accuracy: 0.9979 - val_loss: 0.0353 - val_accuracy: 0.9975\n",
      "Epoch 32/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0326 - accuracy: 0.9984 - val_loss: 0.0305 - val_accuracy: 0.9980\n",
      "Epoch 33/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0282 - accuracy: 0.9986 - val_loss: 0.0264 - val_accuracy: 0.9990\n",
      "Epoch 34/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0243 - accuracy: 0.9991 - val_loss: 0.0229 - val_accuracy: 0.9990\n",
      "Epoch 35/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0209 - accuracy: 0.9992 - val_loss: 0.0196 - val_accuracy: 0.9990\n",
      "Epoch 36/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0178 - accuracy: 0.9994 - val_loss: 0.0168 - val_accuracy: 0.9990\n",
      "Epoch 37/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0152 - accuracy: 0.9994 - val_loss: 0.0143 - val_accuracy: 0.9990\n",
      "Epoch 38/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0129 - accuracy: 0.9996 - val_loss: 0.0121 - val_accuracy: 0.9995\n",
      "Epoch 39/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0108 - accuracy: 0.9996 - val_loss: 0.0102 - val_accuracy: 0.9995\n",
      "Epoch 40/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0091 - accuracy: 0.9998 - val_loss: 0.0086 - val_accuracy: 0.9995\n",
      "Epoch 41/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0076 - accuracy: 0.9999 - val_loss: 0.0073 - val_accuracy: 0.9995\n",
      "Epoch 42/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 0.0060 - val_accuracy: 1.0000\n",
      "Epoch 43/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
      "Epoch 44/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
      "Epoch 45/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
      "Epoch 46/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
      "Epoch 47/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
      "Epoch 48/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
      "Epoch 49/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
      "Epoch 51/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
      "Epoch 52/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 9.2067e-04 - accuracy: 1.0000 - val_loss: 8.4142e-04 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 7.6033e-04 - accuracy: 1.0000 - val_loss: 6.9310e-04 - val_accuracy: 1.0000\n",
      "Epoch 54/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 6.3107e-04 - accuracy: 1.0000 - val_loss: 5.7342e-04 - val_accuracy: 1.0000\n",
      "Epoch 55/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 5.2603e-04 - accuracy: 1.0000 - val_loss: 4.7687e-04 - val_accuracy: 1.0000\n",
      "Epoch 56/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.7525e-04 - accuracy: 1.0000 - val_loss: 4.6821e-04 - val_accuracy: 1.0000\n",
      "Epoch 57/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.6676e-04 - accuracy: 1.0000 - val_loss: 4.5959e-04 - val_accuracy: 1.0000\n",
      "Epoch 58/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.5842e-04 - accuracy: 1.0000 - val_loss: 4.5114e-04 - val_accuracy: 1.0000\n",
      "Epoch 59/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.5024e-04 - accuracy: 1.0000 - val_loss: 4.4281e-04 - val_accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.4224e-04 - accuracy: 1.0000 - val_loss: 4.3474e-04 - val_accuracy: 1.0000\n",
      "Epoch 61/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3784e-04 - accuracy: 1.0000 - val_loss: 4.3394e-04 - val_accuracy: 1.0000\n",
      "Epoch 62/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3706e-04 - accuracy: 1.0000 - val_loss: 4.3314e-04 - val_accuracy: 1.0000\n",
      "Epoch 63/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3628e-04 - accuracy: 1.0000 - val_loss: 4.3235e-04 - val_accuracy: 1.0000\n",
      "Epoch 64/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3550e-04 - accuracy: 1.0000 - val_loss: 4.3155e-04 - val_accuracy: 1.0000\n",
      "Epoch 65/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3472e-04 - accuracy: 1.0000 - val_loss: 4.3076e-04 - val_accuracy: 1.0000\n",
      "Epoch 66/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3429e-04 - accuracy: 1.0000 - val_loss: 4.3067e-04 - val_accuracy: 1.0000\n",
      "Epoch 67/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3421e-04 - accuracy: 1.0000 - val_loss: 4.3059e-04 - val_accuracy: 1.0000\n",
      "Epoch 68/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3413e-04 - accuracy: 1.0000 - val_loss: 4.3051e-04 - val_accuracy: 1.0000\n",
      "Epoch 69/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3405e-04 - accuracy: 1.0000 - val_loss: 4.3043e-04 - val_accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3397e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 71/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 72/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 73/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 74/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 75/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 76/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 77/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 78/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 79/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 81/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 82/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 83/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 84/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 85/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 86/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 87/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 88/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 89/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "160/160 [==============================] - 0s 2ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 91/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 92/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 93/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 94/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 95/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 96/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 97/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 98/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 99/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "160/160 [==============================] - 0s 1ms/step - loss: 4.3393e-04 - accuracy: 1.0000 - val_loss: 4.3035e-04 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(1, kernel_size=5, input_shape = (15, 4), padding='valid', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "#optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(\n",
    "    optimizer='rmsprop',\n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n",
    "model.summary()\n",
    "print(strings_train.shape)\n",
    "\n",
    "history = model.fit(\n",
    "    strings_train, labels_train,\n",
    "    batch_size=50,\n",
    "    epochs = 100,\n",
    "    validation_data = (strings_test, labels_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt, bias = model.layers[0].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.8652016 ],\n",
       "        [-2.8558435 ],\n",
       "        [-2.8558435 ],\n",
       "        [-2.8558462 ]],\n",
       "\n",
       "       [[-2.2992623 ],\n",
       "        [ 1.4217831 ],\n",
       "        [-2.2994955 ],\n",
       "        [-2.2992618 ]],\n",
       "\n",
       "       [[-2.479928  ],\n",
       "        [-2.4799278 ],\n",
       "        [ 1.2411165 ],\n",
       "        [-2.4799278 ]],\n",
       "\n",
       "       [[-2.7438388 ],\n",
       "        [-2.743841  ],\n",
       "        [-2.7438395 ],\n",
       "        [ 0.97720695]],\n",
       "\n",
       "       [[ 0.7210865 ],\n",
       "        [-2.999962  ],\n",
       "        [-2.9999592 ],\n",
       "        [-2.9999602 ]]], dtype=float32)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27471b75a30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 15, 25)            525       \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 375)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 376       \n",
      "=================================================================\n",
      "Total params: 901\n",
      "Trainable params: 901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(8000, 15, 4)\n",
      "Epoch 1/20\n",
      "1600/1600 [==============================] - 1s 719us/step - loss: 0.6834 - accuracy: 0.5585 - val_loss: 0.6580 - val_accuracy: 0.6200\n",
      "Epoch 2/20\n",
      "1600/1600 [==============================] - 1s 660us/step - loss: 0.6543 - accuracy: 0.6083 - val_loss: 0.6531 - val_accuracy: 0.5965\n",
      "Epoch 3/20\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.6436 - accuracy: 0.6216 - val_loss: 0.6391 - val_accuracy: 0.6220\n",
      "Epoch 4/20\n",
      "1600/1600 [==============================] - 1s 677us/step - loss: 0.6270 - accuracy: 0.6465 - val_loss: 0.6105 - val_accuracy: 0.6735\n",
      "Epoch 5/20\n",
      "1600/1600 [==============================] - 1s 676us/step - loss: 0.5721 - accuracy: 0.7156 - val_loss: 0.5297 - val_accuracy: 0.7515\n",
      "Epoch 6/20\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.4781 - accuracy: 0.8026 - val_loss: 0.4237 - val_accuracy: 0.8560\n",
      "Epoch 7/20\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.3808 - accuracy: 0.8721 - val_loss: 0.3341 - val_accuracy: 0.9030\n",
      "Epoch 8/20\n",
      "1600/1600 [==============================] - 1s 669us/step - loss: 0.3016 - accuracy: 0.9081 - val_loss: 0.2595 - val_accuracy: 0.9315\n",
      "Epoch 9/20\n",
      "1600/1600 [==============================] - 1s 662us/step - loss: 0.2405 - accuracy: 0.9310 - val_loss: 0.2064 - val_accuracy: 0.9535\n",
      "Epoch 10/20\n",
      "1600/1600 [==============================] - 1s 656us/step - loss: 0.1935 - accuracy: 0.9473 - val_loss: 0.1632 - val_accuracy: 0.9675\n",
      "Epoch 11/20\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.1569 - accuracy: 0.9635 - val_loss: 0.1347 - val_accuracy: 0.9780\n",
      "Epoch 12/20\n",
      "1600/1600 [==============================] - 1s 663us/step - loss: 0.1278 - accuracy: 0.9736 - val_loss: 0.1216 - val_accuracy: 0.9815\n",
      "Epoch 13/20\n",
      "1600/1600 [==============================] - 1s 657us/step - loss: 0.1045 - accuracy: 0.9799 - val_loss: 0.0891 - val_accuracy: 0.9880\n",
      "Epoch 14/20\n",
      "1600/1600 [==============================] - 1s 672us/step - loss: 0.0855 - accuracy: 0.9837 - val_loss: 0.0737 - val_accuracy: 0.9860\n",
      "Epoch 15/20\n",
      "1600/1600 [==============================] - 1s 661us/step - loss: 0.0711 - accuracy: 0.9866 - val_loss: 0.0619 - val_accuracy: 0.9875\n",
      "Epoch 16/20\n",
      "1600/1600 [==============================] - 1s 667us/step - loss: 0.0594 - accuracy: 0.9893 - val_loss: 0.0528 - val_accuracy: 0.9935\n",
      "Epoch 17/20\n",
      "1600/1600 [==============================] - 1s 668us/step - loss: 0.0496 - accuracy: 0.9902 - val_loss: 0.0437 - val_accuracy: 0.9935\n",
      "Epoch 18/20\n",
      "1600/1600 [==============================] - 1s 745us/step - loss: 0.0418 - accuracy: 0.9919 - val_loss: 0.0363 - val_accuracy: 0.9940\n",
      "Epoch 19/20\n",
      "1600/1600 [==============================] - 1s 694us/step - loss: 0.0351 - accuracy: 0.9934 - val_loss: 0.0317 - val_accuracy: 0.9960\n",
      "Epoch 20/20\n",
      "1600/1600 [==============================] - 1s 681us/step - loss: 0.0296 - accuracy: 0.9945 - val_loss: 0.0282 - val_accuracy: 0.9970\n"
     ]
    }
   ],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(25, kernel_size=5, input_shape = (15, 4), padding='same', activation='sigmoid'))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\n",
    "    optimizer = Adam(lr=0.001)\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss='binary_crossentropy', \n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    model.summary()\n",
    "    print(strings_train.shape)\n",
    "\n",
    "    history = model.fit(\n",
    "        strings_train, labels_train,\n",
    "        batch_size=5,\n",
    "        epochs = 20,\n",
    "        validation_data = (strings_test, labels_test)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
